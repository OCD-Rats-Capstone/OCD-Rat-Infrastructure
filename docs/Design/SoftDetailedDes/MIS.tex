\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\allowdisplaybreaks

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \url{https://github.com/OCD-Rats-Capstone/OCD-Rat-Infrastructure/blob/main/docs/SRS-Volere/SRS.pdf}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for
\textbf{RatBat2}, a data analysis web application designed to visualize, query, and process behavioural data from experiments involving rats with Obsessive-Compulsive Disorder (OCD). The system enables researchers to upload experimental trial data, perform natural language–based searches, and generate dynamic visualizations for behavioural comparisons and trend analysis.

Complementary documents include the \textit{System Requirements Specification (SRS)} and \textit{Module Guide (MG)}.  
The full documentation and implementation can be found at  
\url{https://github.com/OCD-Rats-Capstone/OCD-Rat-Infrastructure}.


\section{Notation}

This document adopts a formal notation and structural convention to describe the architecture and module interface specifications (MIS) for the Behavioral Data Analysis Platform for Animal Models of OCD. 

The structure of each MIS follows the framework of \citet{HoffmanAndStrooper1995}, extended to incorporate template modules as described by \citet{GhezziEtAl2003}. The mathematical and logical notation is consistent with Chapter 3 of \citet{HoffmanAndStrooper1995}, with domain-specific adaptations for data processing and behavioral event analysis.

\subsection*{Mathematical and Logical Conventions}

\begin{itemize}
    \item The symbol \texttt{:=} denotes an assignment or multiple assignment statement.  
    For example, \texttt{session.avg\_latency := sum(latency) / count(latency)}.

    \item Conditional expressions follow the form:
    \[
        (c_1 \Rightarrow r_1 \;|\; c_2 \Rightarrow r_2 \;|\; \dots \;|\; c_n \Rightarrow r_n)
    \]
    For instance:
    \[
        (\text{event.type = "drug 1"} \Rightarrow \text{increment(count)} \;|\; \text{event.type = "drug 2"} \Rightarrow \text{record(duration)})
    \]
    where the rule corresponding to the first true condition is applied.

    \item Logical connectives are used as follows:
    \begin{itemize}
        \item \(\land\) — logical AND  
        \item \(\lor\) — logical OR  
        \item ` — logical NOT  
        \item \(\Rightarrow\) — implication
    \end{itemize}

    \item Set notation follows standard mathematical conventions:  
    \(\{x \mid P(x)\}\) represents the set of all \(x\) satisfying predicate \(P(x)\).  
    Example:  
    \(\{ e \in Events \mid e.duration > 10s \}\) denotes the set of long-duration events.

    \item Ranges are denoted as \([a..b]\), representing all integer time indices \(t\) such that \(a \leq t \leq b\).

    \item Function definitions are expressed as mappings:  
    \[
        f : Input \rightarrow Output
    \]
    Example:  
    \[
        \texttt{computeMetrics} : SessionData \rightarrow BehavioralSummary
    \]
\end{itemize}

\subsection*{Data and Type Notation}

\begin{itemize}
    \item \(Session\) — a structured dataset representing a single experimental trial.  
    \item \(Event\) — a tuple of attributes describing a behavioral observation, e.g. \((type, timestamp, duration)\).
    \item \(Metric\) — a computed quantitative value derived from one or more events.
    \item \(AnimalID\) — a unique identifier for a subject.
    \item \(TrialSet := \{ s_1, s_2, ..., s_n \}\) — the set of all sessions recorded for a given animal.
\end{itemize}

\par{Generally python notation or something similar will be used for data types which is outlined below. Additionally, some additional data types are outlined in this section.
For simplicity, some data types will be desribed in simple language. }
\begin{center}
\begin{tabular}{ |c|c| } 
\hline
Data Type & Notation \\
\hline
Integer & int \\ 
\hline
String & String \\
\hline
Float & float \\
\hline
JSON Object & JSON Object \\
\hline
HTTP Response/Request & HTTP Response/Request \\
\hline
File & File \\
\hline
$[]$ & Array of the prepended data type (e.g. int$[]$) \\
\hline
$\{\}$ & Map of prepended data type (e.g. String$\{\}$) \\
\hline
SQL Query & SQL Query \\
\hline
Boolean & bool \\

\hline
\end{tabular}
\end{center}

\subsection*{Units and Measurement Conventions}
\begin{itemize}
    \item Time values are expressed in seconds (s).  
    \item Counts and frequencies are represented as integers.  
    \item Statistical metrics (e.g., mean, standard deviation, z-score) are expressed as real numbers (\(\mathbb{R}\)).
\end{itemize}

These conventions are used consistently throughout the system specification to ensure mathematical clarity and facilitate unambiguous interpretation of the behavioral data models, algorithms, and transformations.


\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
  \centering
  \begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
  \toprule
  \textbf{Level 1} & \textbf{Level 2}\\
  \midrule
  
  {Hardware-Hiding Module} & ~ \\
  \midrule
  
  \multirow{3}{0.3\textwidth}{Behaviour-Hiding Module} & Front-End Interface Module\\
  & API Layer Module\\
  & Data Schema and Storage Module\\
  & Data Visualization Module\\
  \midrule
  
  \multirow{4}{0.3\textwidth}{Software Decision Module} & NLP Query Processor \\
  & Data Processing Pipeline Module\\
  & Authentication and Access Control Module\\
  & Fault and Error Management Module\\
  \bottomrule
  
  \end{tabular}
  \caption{Module Hierarchy}
  \label{TblMH}
  \end{table}
\newpage

\section{MIS of M1: Hardware-Hiding Module} \label{Module 1}

\subsection{Module}

\par{The hardware hiding module will be implemented by the native OS of the machine running our system. This will not be designed by us. For
detailed design implementation please see the breakdown of the OS of the local machine running our system's web page (client-side) or the 
Linux-based OS of the server hosting our system's backend and database.}

\section{MIS of M2: Query Processor Module} \label{Module 2}

\subsection{Module}

NLPModule

\subsection{Uses}

\begin{itemize}
    \item M9: Fault and Error Management
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}

\par

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{4cm} p{4cm} p{4cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
NLP Processor & String & String & incoherent prompt, empty input \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\par{None}

\subsubsection{Environment Variables}

\begin{itemize}

  \item{$LLM\_API\_KEY$: String}
  \item{$System\_Prompt$: String}
  \item{$Schema\_Attributes$: String{}}
  \item{$Valid\_Operators$: String{}}

\end{itemize}

\subsubsection{Assumptions}

\begin{itemize}

  \item{The system prompt environment variable will provide enough information to the LLM to ensure that the returned response string conforms exactly
  to the structure of the needed input format for a database query.}
  \item{The large language model used to process the natural language input into database commands will require the use of an API key and will not
  be locally hosted, thus the need for an API key environment variable.}


\end{itemize}


\subsubsection{Access Routine Semantics}

\noindent $NLP\_Processor(String: natural\_language) \rightarrow String$:
\begin{itemize}
\item output: out := if $(is\_valid\_output(natural\_language))~then~
\\ \{LLM\_API\_Response(natural\_language)\}~else~\{raise~incoherent\_prompt\}$ 
\item exceptions: $(natural\_language$ IS NULL $=> empty\_input), (!is\_valid\_output(natural\_language) => incoherent\_prompt)$
\end{itemize}

\subsubsection{Local Functions}

\noindent $is\_valid\_output(String: LLM\_Response) \rightarrow bool$
\begin{itemize}
\item output: out := $($b such that b $\in ([x \in Schema\_Attributes];[y \in Valid\_Operators];[<Value>]))$
\end{itemize}

\noindent $LLM\_API\_Call(String: natural\_language, String: System\_Prompt) \rightarrow String$
\begin{itemize}
\item $output: LLM\_Response := (Call~LLM~API~where: \\ Prompt input = natural\_language~prepended~by~System\_Prompt)$
\end{itemize}



\section{MIS of M3: Front-End Interface Module} \label{Module 3}

\subsection{Module}

FrontEnd

\subsection{Uses}

\begin{itemize}
    \item M7: Data Processing Pipeline Module
    \item M4: API Layer Module
    \item M6: Data Visualization Module
    \item M9: Fault and Error Management Module
    \item M8: Authentication and Access Control Module
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}

\par{N/A}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{4cm} p{5cm} p{3cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
Submit Search Query & QueryParameters & DisplayedResults & invalid query \\
Apply Filter & FilterCriteria & UpdatedResults & invalid filter \\
Render Visualization & VisualizationConfig, DataSet & RenderedChart & unsupported chart type \\
Download Data & FormatType, DataSet & File & unsupported format, empty dataset \\
\hline
\end{tabular}
\end{center}


\subsection{Semantics}

\subsubsection{State Variables}

\begin{itemize}
  \item{NavPage: String (URL)}
  \item{HTTPStatusCode: int}
  \item{UserInterfaceComponents: {bool, String, int, char} (Variables which provide values to UI components such as a checkbox being checked or the value
  in an input box. Aggregated as it would be a waste of time to list each individual component and it's state variable(s))}
  \item{DataSet: JSON Object}
\end{itemize}

\subsubsection{State Invariant}

\begin{itemize}
  \item{$NavPage \in \{FrontEndURLs\}$ }
  \item{$HTTPStatusCode \in \{$Standard HTTP Status Codes$\}$}
\end{itemize}

\subsubsection{Environment Variables}

  \begin{itemize}
    \item{BackEndLocation: String (URL for HTTP request destinations)}
    \item{FrontEndURLs: String{}}
  \end{itemize}

\subsubsection{Assumptions}

\begin{itemize}
  \item{Only one backend location will be necessary. HTTP request body will contain sufficient information to call the correct corresponding
  module and serve the proper response.}
  \item{Front end module will be free of explicit business logic and will simply package user input and serve output responded. Aggregating user input,
  formatting HTTP requests and serving responses are the extent of the front end requirements.}
\end{itemize}
\subsubsection{Access Routine Semantics}

\par{N/A}

\subsubsection{Local Functions}

\par{$HTTP\_Send\_Request(HTTP~Request: HTTP\_request) \rightarrow HTTP\_Response$: }
\begin{itemize}
  \item{output: $out := HTTP\_response~from~backend~modules$}
  \item{exception: None}
\end{itemize}

\par{$Nav\_Page(String: Nav\_URL):$ }
\begin{itemize}
  \item{$transition: NavPage := Nav\_URL$}
  \item{$exception: exc := (NavPage = bad~URL => page\_not\_found)$}
\end{itemize}

\par{$HTTP\_Error\_Handle(HTTP~Response: HTTP\_response):$ }
\begin{itemize}
  \item{$transition: HTTPStatusCode := HTTP\_response.StatusCode, NavPage := \\'Initial~Landing~Page', UserInterfaceComponents := \{$component initial values$\}$ }
  \item{exception: None}
\end{itemize}

\par{$HTTP\_Serve\_Data($JSON Object: DataSet): }
\begin{itemize}
  \item{$transition: DataSet := HTTP\_Send\_Request(HTTP\_request).body$}
  \item{$exception: exc := (HTTP\_Send\_Request(HTTP\_request).body == NULL =>$ Empty HTTP Response)}

\end{itemize}

\section{MIS of M4: API Layer Module} \label{Module 4}

\subsection{Module}

APILayer

\subsection{Uses}

\begin{itemize}
    \item M5: Data Schema and Storage Module
    \item M2: NLP Query Processor Module
    \item M8: Authentication and Access Control Module
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}

\par{N/A}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{4cm} p{5cm} p{3cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
Process Structured Query & StructuredQuery & JSON Object & malformed query, empty result \\
Process NLP Query &  NaturalLanguageQuery & JSON Object & unrecognized intent, NLP failure \\
Get Dataset & QueryResultID & DataSet (JSON) & invalid ID, empty dataset \\
Request RawFiles & DataSet\{"FileLocations"\} & File[] & bad URL, missing files \\
Authenticate Request & AuthToken & AccessDecision & invalid token \\
\hline
\end{tabular}
\end{center}


\subsection{Semantics}

\subsubsection{State Variables}

\begin{itemize}
  \item{$QueryType: String \in \{'NaturalLanguage','Structured'\}$}
  \item{ModuleHasData: bool}
  \item{Dataset: JSON Object}
  \item{RequestedQuery: SQL Query}


\end{itemize}

\subsubsection{Environment Variables}

  \begin{itemize}
    \item{HostedDatabaseEndPoint: String (URL for Database Connection)}
    \item{DatabaseAccessKey: String}
    \item{FRDRDataSetEndPoint: String (URL EndPoint for Dr.Szechtman's Data Sets in the FRDR repository)}
    \item{BaseQuery: SQL Query (To be augmented by requested filters)}
  \end{itemize}

\subsubsection{Assumptions}

\begin{itemize}
  \item{Only one instance of our database will be hosted and thus, one hardcoded endpoint will be sufficient for handling our database connection. Additionally,
  a single access key will be sufficient to provide all users access to the database connection.}
  \item{The Endpoint for accessing Dr.Szechtman's datasets on the FRDR website will not change.}
  \item{The disk space available on the application server will be sufficient to temporarily download several .CSV or .MPG files files from FRDR for
  processing purposes.}
  \item{A boilerplate query for the database will be sufficient for every unique query, only needing to be augmented algorithmically through the requested
  filters.}
\end{itemize}
\subsubsection{Access Routine Semantics}

\noindent $Get\_Dataset() \rightarrow File[]$:
\begin{itemize}
\item output: out := DataSet
\item exceptions: exc:= (HasData := False $=>$ empty\_dataset), exc := ($HTTP\_Response \in \{4++\}$)
\end{itemize}

\noindent $Request\_RawFiles(JSON~Object: DataSet): \rightarrow File[]$
\begin{itemize}
  \item{$transition: out := $Array of files provided via automatic downloads faciliatated by \\ HTTP requests to the DataSet\{"FileLocations"\} Attribute}
  \item{$exception: exc := (HasData := False => Empty\_Result), \\ exc := (Database~Connection~Unsuccessful => Connection\_Refused)$}

\end{itemize}

\subsubsection{Local Functions}

\par{$Choose\_Query\_Process(String: QueryType) \rightarrow JSON~Object$: }
\begin{itemize}
  \item{transition: $ DataSet := if (QueryType == 'NaturalLanguage') \{NLP\_Query(HTTP\_Request)\} \\ elseif (QueryType == 'Structured') \{Structured\_Query(HTTP\_Request)\}$}
  \item{exception: $exc := (\not(QueryType \in \{'NaturalLanguage','Structured'\}) => Bad\_Query\_Type$)}
\end{itemize}

\noindent{$NLP\_Query(HTTP~Request: HTTP\_Request): \rightarrow SQL~Query$ }
\begin{itemize}
  \item{$transition: RequestedQuery := $ Augmented Base Query Based on Output of NLPModule.NLP\_Processor(HTTP\_Request.body)}
  \item{$exception: exc := (HTTP\_Request.body~IS~NULL => empty\_filters)$}
\end{itemize}

\noindent{$Structured\_Query(HTTP~Response: HTTP\_response): \rightarrow SQL~Query$ }
\begin{itemize}
  \item{$transition: RequestedQuery := $ Augmented Base Query Based on filters in HTTP\_Request.body}
  \item{$exception: exc := (HTTP\_Request.body~IS~NULL => empty\_filters)$}
\end{itemize}

\noindent{$Request\_DataSet(SQL~Query: RequestedQuery, String: HostedDatabaseEndPoint): \rightarrow JSON~Object$}
\begin{itemize}
  \item{$transition: DataSet := $JSON Object generated from result of RequestedQuery API request at URL of HostedDatabaseEndPoint}
  \item{$transition: if(DataSet~IS~NOT~NULL) \{HasData := True\}$}
  \item{$exception: exc := ( HasData := False => Empty\_Result), exc := \\ (Database Connection Unsuccessful => Connection\_Refused)$}

\end{itemize}

\section{MIS of M5: Data Schema and Storage Module} \label{Module 5}

\subsection{Module}

DataBaseSchema \\

\par{\textbf{Note: }It does not make sense to outline this as a typical module with functions, variables etc... since this module consists of our database schema
	for querying the experimental data relevant to this project. As a result, this module will be outlined via the schema definition of our database.
  Also note that our team and Dr.Szechtman have already worked to develop a schema that makes sense based on Dr.Szechtman's understanding of the datasets.
  Thus, this will be very detailed and specific, more so than is likely necessary but since the work has already been done, the full design will be
  outlined.}

\subsection{Schema Overview}

\subsubsection{Core Entity Tables}

\begin{itemize}

	\item{1. apparatuses - Testing Equipment}
	\item{2. rats - Subject Animals}
	\item{3. brain\_mainpulations - Surgical interventions}
	\item{4. drug\_rx - Drug regimen combinations}
	\item{5. drug\_rx\_details - Individual compound specifications}

\end{itemize}

\subsubsection{Reference Tables}

\begin{itemize}

	\item{6. light\_cycles - Colony room light/dark cycles}
	\item{7. session\_types - Session classification codes}
	\item{8. testers - Experimenter identifiers}
	\item{9. apparatus\_patterns - Object arrangement configurations}
	\item{10. drugs - Pharmacological agents}
	\item{11. brain\_regions - Brain region codes}
	\item{12. testing\_rooms - Physical testing locations}

\end{itemize}

\subsubsection{Experimental Session Tables}

\begin{itemize}

	\item{13. experimental\_sessions - All 20,491 experimental sessions}
	\item{14. session\_drug\_details - Drug administration for experimental sessions}

\end{itemize}

\subsubsection{Histology and Video Tables}

\begin{itemize}

	\item{15. histology\_results – Post-mortem lesion verification}
	\item{16. movie\_files – Video file metadata}

\end{itemize}

\subsubsection{Data File Locations Table}

\begin{itemize}

	\item{17. data\_file\_locations – Physical storage locations (336,507 records)}

\end{itemize}

\subsubsection{Session Data Files and Observations Tables}

\begin{itemize}

	\item{18. session\_data\_files – Session-to-data-file linking}
	\item{19. session\_observations – Quality control and notes}

\end{itemize}

\subsection{Schema Definition}

\begin{itemize}

\item 1. apparatuses - Testing Equipment
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE apparatuses (apparatus\_id SERIAL PRIMARY KEY, apparatus\_name VARCHAR(100), apparatus\_code VARCHAR(10),
	      testing\_room\_id INTEGER REFERENCES testing\_rooms(room\_id),
	      \\ apparatus\_location\_in\_room VARCHAR(50),
	      apparatus\_notes TEXT);}
	\item{\textbf{Referenced By: }experimental\_sessions \textbf{Foreign Key: }apparatus\_id (Many-to-One: many sessions use same apparatus)}
\end{itemize}
\item 2. rats - Subject Animals
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE rats (
	      rat\_id SERIAL PRIMARY KEY,
	      legacy\_rat\_id VARCHAR(20) UNIQUE,
	      sex VARCHAR(10),
	      light\_cycle\_id INTEGER REFERENCES light\_cycles(light\_cycle\_id),
	      strain VARCHAR(50),
	      birth\_date DATE
	      );
	      }
	\item{\textbf{Referenced By: }experimental\_sessions \textbf{Foreign Key: }rat\_id (One-to-Many: one rat, many sessions)}
	\item{\textbf{Referenced By: }brain\_manipulations \textbf{Foreign Key: }rat\_id (One-to-Many: one rat can have multiple manipulations)}
\end{itemize}
\item 3. brain\_mainpulations - Surgical interventions
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE brain\_manipulations (
	      manipulation\_id SERIAL PRIMARY KEY,
	      rat\_id INTEGER REFERENCES rats(rat\_id),
	      surgery\_type VARCHAR(50),
	      target\_region\_id INTEGER REFERENCES brain\_regions(region\_id),
	      surgery\_date DATE
	      );

	      }
	\item{\textbf{Referenced By: }histology\_results table \textbf{Foreign Key: }manipulation\_id (One-to-One: each lesion has histology assessment)}
\end{itemize}
\item 4. drug\_rx - Drug regimen combinations
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE drug\_rx (
	      drug\_rx\_id SERIAL PRIMARY KEY,
	      rx\_label VARCHAR(200),
	      num\_drugs INTEGER,
	      notes\_drug\_rx TEXT
	      );

	      }
	\item{\textbf{Referenced By: }experimental\_sessions \textbf{Foreign Key: }drug\_rx\_id (Many-to-One: many sessions use same regimen)}
	\item{\textbf{Referenced By: }drug\_rx\_details  \textbf{Foreign Key: }drug\_rx\_id (One-to-Many: each regimen has multiple detail records)}
\end{itemize}

\item 5. drug\_rx\_details - Individual compound specifications

\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE drug\_rx\_details (
	      drug\_rx\_detail\_id SERIAL PRIMARY KEY,
	      drug\_rx\_id INTEGER REFERENCES drug\_rx(drug\_rx\_id),
	      drug\_id INTEGER REFERENCES drugs(drug\_id),
	      prescribed\_dose NUMERIC(10,6),
	      dose\_unit VARCHAR(50),
	      route VARCHAR(50),
	      time\_before\_session\_hours NUMERIC(10,2)
	      );


	      }
\end{itemize}

\item light\_cycles
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE light\_cycles (light\_cycle\_id SERIAL PRIMARY KEY, cycle\_name VARCHAR(50) NOT NULL, lights\_on\_time TIME, lights\_off\_time TIME);}
	\item{\textbf{Referenced By: }rats \textbf{Foreign Key: }light\_cycle\_id (Many-to-One: many rats share same light cycle)}
\end{itemize}
\item session\_types - Session classification codes
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE session\_types (session\_type\_id SERIAL PRIMARY KEY, type\_name VARCHAR(100) NOT NULL, session\_types\_notes TEXT);}
	\item{\textbf{Referenced By: }experimental\_sessions \textbf{Foreign Key: }session\_type\_id (Many-to-One: many sessions can be the same type)}
\end{itemize}
\item 8. testers - Experimenter identifiers
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE testers (tester\_id SERIAL PRIMARY KEY, first\_last\_name VARCHAR(100), initials VARCHAR(10));}
	\item{\textbf{Referenced By: }experimental\_sessions \textbf{Foreign Key: }tester\_id (Many-to-One: each tester conducted many sessions)}
\end{itemize}
\item 9. apparatus\_patterns - Object arrangement configurations
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE apparatus\_patterns (pattern\_id SERIAL PRIMARY KEY, pattern\_description TEXT);}
	\item{\textbf{Referenced By: }experimental\_sessions \textbf{Foreign Key: }pattern\_id (Many-to-One: many sessions use the same pattern)}
\end{itemize}
\item 10. drugs - Pharmacological agents
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE drugs (drug\_id SERIAL PRIMARY KEY, drug\_abbreviation VARCHAR(20), drug\_name
	      VARCHAR(200), drug\_is\_active BOOLEAN, dose\_unit VARCHAR(20), drugs\_notes TEXT);}
	\item{\textbf{Referenced By: }drug\_rx\_details \textbf{Foreign Key: }drug\_id (Many-to-One: specifies drugs in prescription regimens)}
	\item{\textbf{Referenced By: }session\_drug\_details \textbf{Foreign Key: }drug\_id (Many-to-One: records actual drugs administered)}
\end{itemize}
\item 11. brain\_regions - Brain region codes
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE brain\_regions (region\_id SERIAL PRIMARY KEY, region\_name VARCHAR(100), region\_abbreviation VARCHAR(20));}
	\item{\textbf{Referenced By: }brain\_manipulations \textbf{Foreign Key: }target\_region\_id (Many-to-One: many rats received surgery targeting the same brain region)}
\end{itemize}
\item 12. testing\_rooms - Physical testing locations
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE testing\_rooms (room\_id SERIAL PRIMARY KEY, room\_name VARCHAR(50), room\_notes
	      TEXT);}
	\item{\textbf{Referenced By: }apparatuses \textbf{Foreign Key: }testing\_room\_id (Many-to-One: multiple apparatus can be in the same room)}
\end{itemize}

\item 13. experimental\_sessions - All 20,491 experimental sessions
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE experimental\_sessions (session\_id SERIAL PRIMARY KEY, legacy\_session\_id VARCHAR(7)
	      UNIQUE, session\_type\_id INTEGER REFERENCES session\_types(session\_type\_id), rat\_id INTEGER
	      REFERENCES rats(rat\_id), body\_weight\_grams NUMERIC(6,2), drug\_rx\_id INTEGER REFERENCES
	      drug\_rx(drug\_rx\_id), tester\_id INTEGER REFERENCES testers(tester\_id), effective\_manipulation\_id
	      INTEGER REFERENCES \\ brain\_manipulations(manipulation\_id), apparatus\_id INTEGER REFERENCES
	      apparatuses(apparatus\_id), pattern\_id INTEGER REFERENCES \\ apparatus\_patterns(pattern\_id),
	      locale\_in\_room VARCHAR(20), room\_id INTEGER REFERENCES testing\_rooms(room\_id),
	      testing\_lights\_on SMALLINT, session\_timestamp TIMESTAMP, data\_trial\_id VARCHAR(28),
	      cumulative\_drug\_injection\_number INTEGER);
	      }
	\item{\textbf{Referenced By: }session\_drug\_details \textbf{Foreign Key: } session\_id (One-to-Many. Each session has 1-4 drug detail records specifying actual drugs and doses administered)}
	\item{\textbf{Referenced By: }session\_data\_files \textbf{Foreign Key: }  session\_id (One-to-Many. Each session links to multiple data files (videos, tracks, plots))}
	\item{\textbf{Referenced By: }session\_observations \textbf{Foreign Key: }  session\_id (One-to-Many. Quality control notes and behavioral observations for sessions)}
\end{itemize}
\item 14. session\_drug\_details - Drug administration for experimental sessions

\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE session\_drug\_details (
	      detail\_id SERIAL PRIMARY KEY,
	      session\_id INTEGER REFERENCES experimental\_sessions(session\_id),
	      drug\_id INTEGER REFERENCES drugs(drug\_id),
	      dose\_given NUMERIC(12,5),
	      dose\_unit VARCHAR(20),
	      route VARCHAR(50),
	      time\_before\_session\_hours NUMERIC(10,2),
	      cumulative\_injections\_count\_for\_regimen INTEGER,
	      \\ cumulative\_apparatus\_exposure\_number INTEGER
	      );
	      }
\end{itemize}

\item 15. histology\_results – Post-mortem lesion verification
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE histology\_results (
	      histology\_id SERIAL PRIMARY KEY,
	      manipulation\_id INTEGER REFERENCES \\ brain\_manipulations(manipulation\_id),
	      histology\_status\_id INTEGER REFERENCES lkp\_histology\_status(histology\_status\_id),
	      intact\_status\_id INTEGER REFERENCES functional\_intact\_status(intact\_status\_id),
	      left\_percent\_damage DOUBLE PRECISION,
	      right\_percent\_damage DOUBLE PRECISION,
	      notes\_histology\_results TEXT
	      );}
\end{itemize}
\item 16. movie\_files – Video file metadata
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE movie\_files (
	      movie\_file\_id SERIAL PRIMARY KEY,
	      movie\_file\_name VARCHAR(255),
	      legacy\_movie\_file\_name VARCHAR(255),
	      file\_size\_mb DOUBLE PRECISION,
	      is\_file\_available BOOLEAN,
	      notes\_movie\_files TEXT
	      );}
	\item{\textbf{Referenced By: }session\_data\_files \textbf{Foreign Key: }.movie\_file\_id (Many-to-One: Multiple sessions can reference the same movie file (video multiplexing))}
\end{itemize}
\item 17. data\_file\_locations – Physical storage locations (336,507 records)
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE data\_file\_locations (
	      data\_file\_location\_id SERIAL PRIMARY KEY,
	      data\_file\_id INTEGER REFERENCES session\_data\_files(data\_file\_id),
	      repository\_type\_id INTEGER REFERENCES lkp\_repository\_type(repository\_type\_id),
	      repo\_dataset\_doi VARCHAR(100),
	      repo\_dataset\_name VARCHAR(255),
	      repo\_dataset\_version VARCHAR(24),
	      repo\_file\_url TEXT,
	      is\_primary\_copy BOOLEAN,
	      date\_linked TIMESTAMP,
	      api\_endpoint VARCHAR(255),
	      notes\_data\_file\_locations TEXT
	      );
	      }
\end{itemize}
\item 18. session\_data\_files – Session-to-data-file linking
\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE session\_data\_files (
	      data\_file\_id SERIAL PRIMARY KEY,
	      session\_id INTEGER REFERENCES experimental\_sessions(session\_id),
	      movie\_file\_id INTEGER REFERENCES movie\_files(movie\_file\_id),
	      start\_frame INTEGER,
	      object\_type\_id INTEGER REFERENCES lkp\_data\_file\_object\_type(object\_type\_id),
	      file\_extension VARCHAR(10),
	      file\_name VARCHAR(255),
	      file\_size\_mb DOUBLE PRECISION,
	      notes\_session\_data\_files TEXT
	      );
	      }
	\item{\textbf{Referenced By: }data\_file\_locations \textbf{Foreign Key: }..data\_file\_id (One-to-Many. Each file record has multiple location records (local, FRDR v1, FRDR v2, backups))}
\end{itemize}
\item 19. session\_observations – Quality control and notes

\begin{itemize}
	\item{\textbf{Schema Definition: }CREATE TABLE session\_observations (
	      observation\_id SERIAL PRIMARY KEY,
	      session\_id INTEGER REFERENCES \\ experimental\_sessions(session\_id),
	      observation\_text TEXT,
	      num\_falls\_during\_test INTEGER,
	      falls\_during\_test\_time\_when\_fell\_str VARCHAR(255)
	      );
	      }
\end{itemize}

\end{itemize}

\newpage

\section{MIS of M6: Data Visualization Module} \label{Module 6} 

\subsection{Module}

\textbf{Visualization Engine}


\subsection{Uses}

\begin{itemize}
    \item M4: API Layer Module
    \item M1: Hardware-Hiding Module
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}

This module exports a set of predefined visualization/chart type constants.

\begin{itemize}
  \item \textbf{VTYPE\_BAR} String constant representing bar chart. 
  \item \textbf{VTYPE\_PLOT} String constant representing a general plot area (points, curves). 
  \item \textbf{VTYPE\_PIE} String constant representing a pie chart. 
  \item \textbf{VTYPE\_HEATMAP} String constant representing an (x,y) heatmap. 
  \item \textbf{VTYPE\_TIMESERIES} String constant representing time series (x,y,t) position data. 

\end{itemize}




\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{4cm} p{2cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
GenerateViz & (VType, DataBlob, ChartConfig)  & Viz\_SVG & InvalidDataSchema \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

The Data Visualization Model acts as a stateless data transformation stage and therefore has no associated state variables. 

\subsubsection{Environment Variables}

\begin{itemize}
  \item \textbf{D3\_Library}: External Dependency 
\end{itemize}
\subsubsection{Assumptions}


\begin{itemize}
  \item All input data provided via DataBlob is in valid JSON form.
  \item There will be continued D3 support and existence of all visualization types exported. 
  \item The client environment supports modern SVG standards. 
\end{itemize}


\subsubsection{Access Routine Semantics}

GenerateViz(VType, DataBlob, ChartConfig):
\begin{itemize}
\item  \textbf{Transition:} \textbf{None}
\item  \textbf{Output:} \textbf{Viz\_SVG} (String) representing the rendered D3.js SVG visualization. 
\item[] Note that the image is represented by the XML path string for the resulting SVG. 
\item exception: \textbf{InvalidDataSchema}: Error raised if the JSON DataBlob is incompatible with the specified visualization type.
\item[] For example, most charts are constructed from a tabular form. If this is violated the exception will be raised. 
\end{itemize}

\subsubsection{Local Functions}

\noindent VerifyDataSchema(Data,VType):

\begin{itemize}
  \item \textbf{Purpose:} to check if the JSON data blob conforms to the input specification of the requested visualization. For example, a scatter plot requires 2 vectors for x and y data, while a bar chart requires categorical (key,value) pairs.
  \item \textbf{Output: Boolean} True if valid, False otherwise.  
\end{itemize}

\noindent ApplyD3Template(Data,Type,Config):

\begin{itemize}
  \item \textbf{Purpose:} Convert the validated input data into the specified D3 template, and generate the SVG output. 
  \item \textbf{Output:} SVG (String). 
\end{itemize}


\section{MIS of M7: Data Processing Pipeline Module} \label{Module 7} 

\subsection{Module}

DataProcessingPipeline

\subsection{Uses}
This module interfaces with:

\begin{itemize}
    \item M4: API Layer Module
    \item M9: Fault and Error Management Module
\end{itemize}

\subsection{Syntax}

\subsubsection{Exported Constants}
None.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
ProcessData & Dataset (CSV / JSON), Parameters (dict) & Processed DataFrame / JSON & invalid format, missing fields \\
ComputeMetrics & Processed DataFrame / JSON & Metrics (dict) & empty input, computation error \\
GenerateSummary & Processed DataFrame / JSON & Summary Statistics (dict) & invalid input \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None. All computations are stateless and performed on data inputs provided per request.

\subsubsection{Environment Variables}
\begin{itemize}
    \item \textbf{DATA\_CACHE\_PATH:} String – temporary directory for caching intermediate results.
    \item \textbf{MAX\_WORKERS:} Integer – controls the number of concurrent processing threads.
\end{itemize}

\subsubsection{Assumptions}
\begin{itemize}
    \item Input datasets conform to schema definitions from Data Schema and Storage Module.
    \item Parameters for filtering, grouping, or aggregation are valid and correspond to known attributes.
    \item The environment has sufficient memory and CPU resources for parallel processing.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent ProcessData(Dataset, Parameters) $\rightarrow$ Processed DataFrame:
\begin{itemize}
    \item \textbf{output:} out := cleaned and structured dataset prepared for computation.
    \item \textbf{exception:} invalid format if dataset fails schema validation; missing fields if required attributes are absent.
\end{itemize}

\noindent ComputeMetrics(Processed DataFrame) $\rightarrow$ Metrics:
\begin{itemize}
    \item \textbf{output:} out := computed behavioral metrics (e.g., grooming duration, trial success rate).
    \item \textbf{exception:} empty input if dataset is empty; computation error if numerical operation fails.
\end{itemize}

\noindent GenerateSummary(Processed DataFrame) $\rightarrow$ Summary Statistics:
\begin{itemize}
    \item \textbf{output:} out := dictionary of aggregated statistics (mean, median, standard deviation).
    \item \textbf{exception:} invalid input if DataFrame structure mismatches expected schema.
\end{itemize}

\subsubsection{Local Functions}

\noindent validateInput(Dataset) $\rightarrow$ bool  
\begin{itemize}
    \item \textbf{output:} true if dataset matches schema attributes and expected datatypes.
\end{itemize}

\noindent computeAggregateMetrics(DataFrame) $\rightarrow$ dict  
\begin{itemize}
    \item \textbf{output:} dictionary of computed metrics (e.g., total grooming time, movement variance).
\end{itemize}

\noindent cleanData(Dataset) $\rightarrow$ DataFrame  
\begin{itemize}
    \item \textbf{output:} dataset with missing values handled and outliers removed.
\end{itemize}


\newpage

\section{MIS of M8: Authentication and Access Control Module} \label{Module 8}

\subsection{Module}

\par{The Authentication and Access Control Module is responsible for verifying 
user identities, assigning access roles, and ensuring scalable entry points for users 
that access the software through the web application or through our API clients.}

\subsection{Uses}

None

\par{Additionally, this module will use external libraries, including 
FastAPI's OAuth2PasswordBearer, and JWT libraries for token generation, 
encryption, and validation.}

\subsection{Syntax}

\subsubsection{Exported Constants}

\par{N/A}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{4cm} p{4cm} p{4cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
Login User & String Username, String Password & String JWT Token & InvalidCredentialsError \\
Verify Token & String JWT Token & User Object & TokenExpiredError, InvalidTokenError \\
Get User & String JWT Token & User Object & Authentication Error \\
Authorize Role & User Object, String JWT Token & Boolean & AccessDeniedError \\
Logout User & String JWT Token & Boolean & InvalidTokenError \\
Refresh Token & String JWT Token & String JWT Token & InvalidTokenError, TokenExpiredError \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\begin{itemize}
  \item{User Credentials: A HashMap of usernames to password hashes.}
  \item{Active Tokens: Dictionary of JWT Token Strings mapped to Expiry Timestamps.}
  \item{Permissions Mapping: Dictionary of Role Strings mapped to Permission Strings.}
\end{itemize}

\subsubsection{Environment Variables}

\begin{itemize}
  \item{JWT SECRET KEY: User key used for token signing and verification.}
  \item{MAX CONCURRENT USERS: Maximum allowed concurrent users.}
  \item{NUM CONCURRENT USERS: Number of current concurrent users.}
  \item{USER DATABASE URL: Connection URL to the credential and role management database.}
  \item{TOKEN EXPIRY: Token lifetime configuration for user session.}
\end{itemize}

\subsubsection{Assumptions}

\begin{itemize}
  \item{Authentication requests may orginiate concurrently from both UI or API clients.}
  \item{Passwords are stored securely using a one-way hash.}
  \item{HTTPS is enforced for all login and token exchange operations.}
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent loginUser():
\begin{itemize}
\item transition: Verifies credentials from userCredentials.
\item output: JWT Token as a String.
\item exception: InvalidCredentialsError.
\end{itemize}

\noindent verifyToken():
\begin{itemize}
\item transition: Checks JWT Token signature, expiry time, and status in activeTokens.
\item output: User Object if token is valid.
\item exception: InvalidTokenError or TokenExpiredError.
\end{itemize}

\noindent getUser():
\begin{itemize}
\item transition: None.
\item output: User Object.
\item exception: AuthenticationError.
\end{itemize}

\noindent authorizeRole():
\begin{itemize}
\item transition: None.
\item output: True if authorized, False otherwise.
\item exception: AccessDeniedError.
\end{itemize}

\noindent logoutUser():
\begin{itemize}
\item transition: Removes identifier from activeTokens, logging out the user.
\item output: True if successful, False otherwise.
\item exception: InvalidTokenError.
\end{itemize}

\noindent refreshToken():
\begin{itemize}
\item transition: Validates token and reissues a fresh JWT Token with renewed expiry time.
\item output: JWT Token as a String
\item exception: InvalidTokenError or TokenExpiredError.
\end{itemize}

\subsubsection{Local Functions}

\begin{itemize}
  \item{hashPassword(String password): Generates a secure hash of a user password.}
  \item{createJWTToken(User Object, int expiry): Generates a JWT Token containing user data and expiry period.}
  \item{decodeJWTToken(String JWTToken): Decodes and validates a JWT Token, extracting user data and expiry period.}
  \item{validateUser(String username, String password): Authenticates user via stored credentials.}
\end{itemize}

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}

\newpage

\section{MIS of M9: Fault and Error Management Module} \label{m:M9}

\subsection{Module}

\par{This module is responsible for tracking, logging, alerting, and automatically recovering from errors and faults in the system. It maintains both transient and persistent records of errors, interfaces with dependent modules to capture exceptions, and ensures system reliability and observability.}

\subsection{Uses}

None


\subsection{Syntax}

\subsubsection{Exported Constants}
\begin{itemize}
    \item \texttt{LOG\_LEVELS} – Enumerated type \{DEBUG, INFO, WARNING, ERROR, CRITICAL\} specifying verbosity levels for logging.
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\texttt{logEvent} & message: string, level: LOG\_LEVELS & success: string & ValidationError \\
\hline
\texttt{isTrue} & two variables of the same data type & success: boolean & ValidationError \\
\hline
\texttt{getFaultHistory} & moduleID: string, timeRange: tuple & faultList: list & DatabaseError \\
\hline
\texttt{raiseError} & message: type of error, severity: LOG\_LEVELS & success: boolean & IOError \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
    \item \texttt{errorBuffer}: Temporary queue of recent error events awaiting persistence or notification.
\end{itemize}

\subsubsection{Environment Variables}
\begin{itemize}
    \item Nothing to be listed that fits the criteria.
\end{itemize}

\subsubsection{Assumptions}
\begin{itemize}
    \item All dependent modules provide standardized error codes and messages.
    \item Persistent storage is available for fault logging.
    \item System has sufficient resources (disk space, memory) to maintain logs and state variables.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent \texttt{purgeOldLogs()}:
\begin{itemize}
    \item description: Removes outdated log entries from the system based on the retention policy.
\end{itemize}



\section{Appendix} \label{Appendix}

\newpage{}

\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Problem Analysis and Design.

\input{../../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable? 

  The team was much more focused this deliverable than we had been for the previous deliverable (VnV Plan). Now that
  midterms are over, we had more time to really spend a lot of time trying to do this deliverable well. The previous deliverable
  was less of a priority due to the midterms dwarfing it in terms of grade weight. We think this resulted in a more well done,
  coherent and complete deliverable that puts us in a good spot as we begin the implementation of our system. Additionally, the teamwork
  aspect of this deliverable was also quite good this deliverable. This likely also ties back into having more time in general but group
  members were more willing to take on more parts and help others that needed it. Two members even focused largely on the PoC rather than
  writing the design document because the other three members had the capacity to shoulder a larger documentation load.

  \item What pain points did you experience during this deliverable, and how
    did you resolve them?

    There were not too many major pain points experienced during this deliverable, it generally went quite well. The first pain point of note
    would be ensuring consistency across all parts and between documents. Although we work as a team, we mainly complete the section individually
    and thus we need to ensure that two members don't write things in different sections that are not aligned with each other. This deliverable's sections
    were the most interconnected yet and thus it will require a pretty thorough document review to ensure everything is consistent. The second pain point
    for this deliverable was the MIS design of each module. This was the final section to be completed as we were not quite sure how to split it up or exactly
    what was required. As it turns out this is not just one section but rather a section for each module (so essentially 10 additional sections of the document)
    which was quite a large workload to complete, especially since it was left right until the end. This was simply resolved by splitting up the modules based
    on who had the capacity to take them on and to commit the needed time to completing it. As mentioned earlier, members generally had time to do this so it wasn't
    a terribly painful process.

  \item Which of your design decisions stemmed from speaking to your client(s)
  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
  were not, why, and where did they come from?

    First and foremost, essentially all of module 5 was developed by speaking with our client, Dr. Henry Szechtman. He
    is the definitive expert on these datasets and thus he is most equipped to develop a schema for our system. Luckily, he
    has enough technical knowledge to develop this for us to look over and decide if it is workable, which we believe it is.
    Additionally, the data-processing module, the visualization module and the front-end module were all largely influenced by our discussions
    with Dr.Szechtman, specficially through him describing to us what specific functions he wants the system to have (e.g. data processing abilities,
    front-end design, available visualizations). Outside of these design aspects, most of the rest of the design was created outside of
    much influence from our client. This includes things like the natural language processing module, the fault and error management module, the API
    layer module etc... The reason that these decisions were not made based on client interactions is because they are more purely part
    of what could be called the 'intermediate technical design' rather than user specifications. For example, the natural language processing
    module requires it to be designed such that natural language can be accurately converted into a SQL query. Alternatively, the error management
    module simply regulates UI, API and query inputs to prevent any undesired behaviour. Both of these design outlines do not require
    much input from the client/users as they are basically purely technical implementation (there are not really many different ways to specify natural
    language into a SQL query). As such, they are left to the technical experts which are the members of our group.

  \item While creating the design doc, what parts of your other documents (e.g.
  requirements, hazard analysis, etc), it any, needed to be changed, and why?

  \begin{enumerate}
    \item{Our functional requirement related to serving pre-defined datasets will need to be revised. After further discussion with our client,
          we elicited this requirement in more detail and he is looking more so for a 'web store' outline in the sense that you can sort through
          the available records based on various available categories rather than displaying specific data sets as 'products' which is how we initially
          understood it.}
    \item{Our database schema containing all of the data related to the session trials will now be implemented specifically using a PostGres SQL server.
          This will need to be specified in our SRS.}
    \item{We are not technically using the FRDR API directly because it only serves the metadata for the datasets. Accessing the data objects themselves
          are done via an HTTP request to a specified URL that the FRDR organization provides to us. This is not technically using the API and is rather
          just making HTTP requests to publicly available URLs that exist within the FRDR domain. This requirement should be updated accordingly.}
    \item{Likewise, our hazard related to the API layer should be slightly augmented since we are going to be dealing with HTTP requests. This hazard
    should now focus on hazards related specifically to HTTP such as what could happen due to various error codes and othe related issues that could
    come up.}
    \item{Initially, the idea for our database was that all the data is publicly available to all users at all times. We are beginning to develop
    a new requirement which would both be an addition (as it's a new requirement) and a revision to this publicly available clause. The idea
    is that users can essentially create a materialized view for their experiments and save them on the database so that other users can view them.
    However, in the case that they are not allowed to make the details of their experiment public, we would like to restrict access to this view for a set
    time period (maybe one year after the experiment is created).}
  \end{enumerate}
  \item What are the limitations of your solution?  Put another way, given
  unlimited resources, what could you do to make the project better? (LO\_ProbSolutions)

    A major limitation of our solution is the resources available for running our server and backend. The total amount of disk space taken up by 
    all of the data objects that are relevant to our project is about 11 terabytes. This amount of space is not feasible for our server, not to mention
    the amount of computational resources required to do data processing on all of that data. If this were not an issue, hosting all of the data objects
    on our server without the need to interact with the FRDR API to access the files would greatly streamline the workflow, likely improve performance
    of our system and also give us more control over our implementation without the need to conform and work around the specifications of FRDR.

    A secondary limitation of our system is our access to LLMs and other machine learning models. Natural language processing and behavioural cateogorization are important parts of our
    system. However, we realistically do not have the resources or expertise to develop our own model for these specific purposes and will have to rely
    on Off-The-Shelf software or external systems for these purposes. We can make the best of this by using system prompts to guide the model in the exact direction
    we need it to go, add error checking for coherent results or even train the model with our available data if needed. None of these would be quite as 
    effective as developing a model specifically for the intended purpose of natural language input into query output or behavioral categorizations of rats.

    Finally, maybe the biggest limitation for us is our lack of time. The lack of time is twofold. First, we only have about 6 more months to build the project 
    and secondly, the entire team will likely have 5 other courses happening the entire time we are working on it. It is very common for capstone teams to not
    build anything close to a finalized project, sometimes it doesn't even work at all really. We envision that we will land somewhere in the middle but the time limit
    imposed on us almost guarantees that we will not be able to implement the plethora of integrations desired for this system. From natural language input to extensive
    behavioural categorizations to countless possible visualizations of the datasets and statistical information we could potentially provide that would be useful for
    future researchers, the chances we are able to implement a complete toolbox of these functionalities is slim to none.

  \item Give a brief overview of other design solutions you considered.  What
  are the benefits and tradeoffs of those other designs compared with the chosen
  design?  From all the potential options, why did you select the documented design?
  (LO\_Explores)

  We actually did not consider too many different design options for two reasons. The first is that a previous iteration of this project already
  exists so our supervisor has a general idea of what he wants it to look like and thus we are expected to mostly conform to the general outline
  that was devised by him and last year's team. So, they most broad high level conceptual design was already mostly predetermined when the project started.
  Secondly, when talking about the system architecture, since this will essentially be a full-stack web application with many integrations, it is kind
  of automatically assumed that an MVC architecture or something that approximates that will be used as that is the bog standard for this sort of project.
  Of course, there are many more aspects to the design (especially at slightly higher granularity) that had a couple options for us to decide on. Below are a
  few of possible design alternatives and our reasoning for avoiding them.

  \begin{enumerate}
    \item{Exclusively using the FRDR API to query the relevant data rather than producing a seperate database schema which then points us to the relevant
    endpoints in the FRDR domain. This would allow us to avoid needing to create a database and load all ~20,000 session details into the schema. This
    might have been useful if there were an order of magnitude or two more sessions and storing them ourselves would become an issue. In the end, making
    a schema streamlines the query process and gives us more control over data processing. Furthermore, after investigating the FRDR API, accessing this
    data would have actually been a lot more difficult than we initially had expected.}
    \item{Buying our own personal LLM model (likely would be
    a mostly blank model to be trained) that could run on our application server rather than using an LLM API (such as the OpenAI API). This
    would actually likely improve the accuracy of our prompts if we could train it on the relevant trial data. However, the main concerns with this
    would be the potential lack of data to train it enough to be beneficial (we only have about 20,000 trials, the model may need millions of
    data points) and that it may be quite expensive to purchase a full model for our personal use. In the end, we figured that using an LLM API
    with a sufficient system prompt to guide it's response would be the most cost-effective route that we are confident will provide good enough
    results for our purposes.}
    \item{This is more of a subtle design alternative but one of our modules handles error detection and fault tolerance. This will provide the means
    to track, log and provide details on the various errors that can be raised by the various different modules (such as bad HTTP requests, invalid
    NLP responses etc...). We heavily considered removing this module and leaving this up to each individual module as we thought it would simplify
    the implementation (one less module after all). However, in the end we decided that having a unified error management module would it make it
    easier to track and manage errors across modules as well as ensure they are reported consistently.}
    \item{Using a different front-end development kit other than React. We considered building the front-end from the ground up using HTML/CSS/JavaScript
    as we felt it would give us more control over the interface and would be more purely our work rather than relying on components created by other people.
    However, in the end we decided that using a React component library to build the front-end user interface would both result in a better looking final
    product (we are not graphic designers and thus a React component library will certainly look better than what we could make) and offloading our effort
    to a component library will open up more time for us to implement more backend functionality which is what truly drives the value of this project.}
  \end{enumerate}


\end{enumerate}


\end{document}
